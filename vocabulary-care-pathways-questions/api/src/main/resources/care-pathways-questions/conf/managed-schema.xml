<?xml version="1.0" encoding="UTF-8" ?>

<!--
 * See the NOTICE file distributed with this work for additional
 * information regarding copyright ownership.
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with this program.  If not, see http://www.gnu.org/licenses/
-->

<!--
 For more information, on how to customize this file, please see
 http://wiki.apache.org/solr/SchemaXml
-->

<schema name="care-pathways-questions" version="1.6">
  <types>
    <!-- The StrField type is not analyzed, but indexed/stored verbatim. -->
    <fieldType name="string" class="solr.StrField" sortMissingLast="true"/>

    <!-- A general text field: it tokenizes with ClassicTokenizer,
         removes standard stop words,
         protects keywords defined in "protwords.txt",
         down cases,
         and stems words using the possessive (remove 's)
         and the Porter English stemmer.
         At query time only, it also applies synonyms. -->
    <fieldType name="text_general" class="solr.TextField" positionIncrementGap="100">
      <analyzer type="index">
        <tokenizer class="solr.ClassicTokenizerFactory"/>
        <filter class="solr.StopFilterFactory" ignoreCase="true"/>
        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.EnglishPossessiveFilterFactory"/>
        <filter class="solr.PorterStemFilterFactory"/>
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.ClassicTokenizerFactory"/>
        <filter class="solr.StopFilterFactory" ignoreCase="true"/>
        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.EnglishPossessiveFilterFactory"/>
        <filter class="solr.PorterStemFilterFactory"/>
      </analyzer>
    </fieldType>

    <!-- Field for exact matching of the terms in the query, without stemming
         or other disruptive text processing filters applied to it.
         It is also used to construct a spellcheck index from. It does basic
         tokenization and lowercasing, since it's only used as a source of
         valid words. -->
    <fieldType name="text_spell" class="solr.TextField" positionIncrementGap="100">
      <analyzer type="index">
        <tokenizer class="solr.ClassicTokenizerFactory"/>
        <filter class="solr.ClassicFilterFactory"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.ClassicTokenizerFactory"/>
        <filter class="solr.ClassicFilterFactory"/>
        <filter class="solr.LowerCaseFilterFactory"/>
        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
      </analyzer>
    </fieldType>

    <!-- Field for matching the start of words, useful for matching partial words typed by the user.
         The input text is lowercased and split into tokens,
         then each token is decomposed into prefixes of increasing size,
         starting with the first letter up to at most 10 letters.
         For example, "example" is indexed as:
         e ex exa exam examp exampl example
         The query is also lowecased and tokenized,
         and each such token is matched against the index. -->
    <fieldType name="text_prefix" class="solr.TextField" positionIncrementGap="100">
      <analyzer type="index">
        <tokenizer class="solr.LowerCaseTokenizerFactory"/>
        <filter class="solr.EdgeNGramFilterFactory" minGramSize="1" maxGramSize="10"/>
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.LowerCaseTokenizerFactory"/>
      </analyzer>
    </fieldType>

    <!-- Since fields of this type are by default not stored or indexed,
         any data added to them will be ignored outright. -->
    <fieldtype name="ignored" stored="false" indexed="false" multiValued="true" class="solr.StrField"/>
  </types>

  <fields>
    <field name="version" type="string" indexed="true" stored="true" omitNorms="true"/>
    <field name="id" type="string" indexed="true" stored="true" required="true" omitNorms="true"/>
    <field name="question" type="text_general" indexed="true" stored="true"/>
    <field name="term_group" type="string" indexed="true" stored="true"/>
    <field name="questionSpell" type="text_spell" indexed="true" stored="false"/>
    <field name="questionStub" type="text_prefix" indexed="true" stored="false" omitNorms="true"/>
    <field name="questionSort" type="string" indexed="true" stored="false"/>

    <!-- Catchall field, containing all other searchable text fields (implemented
         via copyField further on in this schema). -->
    <field name="text" type="text_general" indexed="true" stored="false" multiValued="true"/>
    <field name="textSpell" type="text_spell" indexed="true" stored="false" multiValued="true"/>
    <field name="textStub" type="text_prefix" indexed="true" stored="false" multiValued="true" omitNorms="true"/>

    <!-- Discard all other fields -->
    <dynamicField name="*" type="ignored" multiValued="true"/>
  </fields>

  <!-- Field to use to determine and enforce document uniqueness.
       Unless this field is marked with required="false", it will be a required field
    -->
  <uniqueKey>id</uniqueKey>

  <copyField source="question" dest="questionSort"/>
  <copyField source="question" dest="questionSpell"/>
  <copyField source="question" dest="questionStub"/>
  <copyField source="*" dest="text"/>
  <copyField source="*" dest="textSpell"/>
  <copyField source="*" dest="textStub"/>
</schema>
